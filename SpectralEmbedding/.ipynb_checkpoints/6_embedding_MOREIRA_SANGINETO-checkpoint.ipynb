{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4wFZsFB1Vki"
   },
   "source": [
    "### Pair: MOREIRA Luiz Fernando & SANGINETO Marina\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lG2ZQcThCrID"
   },
   "source": [
    "# Graph Learning\n",
    "## Lab 6: Spectral Embedding\n",
    "\n",
    "In this lab, you will learn to embed the nodes of a graph in a vector space of low dimension. We consider the  embedding based on the top eigenvectors of the transition matrix $P=D^{-1}A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z77wg_CxCrIK"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G87_CHXQCrIM",
    "outputId": "f36f749a-300b-4847-8fc9-5aaca6495aa9"
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "!pip install scikit-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "skQR7MIDCrIP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AmbW9qdgCrIR"
   },
   "outputs": [],
   "source": [
    "from sknetwork.data import load_netset, karate_club\n",
    "from sknetwork.embedding import Spectral\n",
    "from sknetwork.ranking import PageRank, top_k\n",
    "from sknetwork.visualization import visualize_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8LakGwZCrIS"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIwwmRb7CrIU"
   },
   "source": [
    "We will work on the following graphs (see the [NetSet](https://netset.telecom-paris.fr/) collection for details):\n",
    "* Openflights (graph)\n",
    "* WikiVitals (directed graph and bipartite graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "511h3XkeCrIV",
    "outputId": "46af213c-90ad-467c-d6ba-71b7a3e9583a"
   },
   "outputs": [],
   "source": [
    "openflights = load_netset('openflights')\n",
    "wikivitals = load_netset('wikivitals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNnS56ihCrIY"
   },
   "source": [
    "## 1. Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtBDq5GuCrIa"
   },
   "source": [
    "## Karate Club\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QcTJFQOCrIc"
   },
   "source": [
    "We first consider the spectral embedding of the [karate club graph](https://en.wikipedia.org/wiki/Zachary%27s_karate_club)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4TlWtb8ZCrId"
   },
   "outputs": [],
   "source": [
    "dataset = karate_club(metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pdann44cCrIe"
   },
   "outputs": [],
   "source": [
    "adjacency = dataset.adjacency\n",
    "position = dataset.position\n",
    "labels_true = dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "PzG8OhVjCrIf",
    "outputId": "26143e4b-fa76-4f18-d86a-815ca1aaeddf"
   },
   "outputs": [],
   "source": [
    "image = visualize_graph(adjacency, position, labels=labels_true)\n",
    "SVG(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAs8OVnbCrIg"
   },
   "source": [
    "## To do\n",
    "\n",
    "* Display the spectrum of the transition matrix (e.g., first 20 eigenvalues).\n",
    "* What does the spectrum suggest?\n",
    "\n",
    "**Answer:** From the spectrum we can see a smooth decay, the second largest eigenvalue is approximately 0.87, which is close to 1, indicating the graph is well connected. Since there aren't a lot of high eigenvalues it probably means that there isn't a clear community separation.\n",
    "\n",
    "* Display the graph with some eigenvectors.\n",
    "* Display the embedding of the graph in dimension 2.\n",
    "* Compare the clusters obtained with the sign of the first component of the embedding to the ground-truth clusters.\n",
    "\n",
    "**Answer:** By observing the plot of the embedding in two dimensions and comparing with the ground-truth labels graph, we can see by the colors a clear separation, indicating two clusters where the ground-truth clusters are. Positive indicates one cluster and negative indicates a different one. As we can see in the plot, some nodes are missclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRAxEEiWCrIh"
   },
   "outputs": [],
   "source": [
    "spectral = Spectral(20, normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IiipWaZFCrIi",
    "outputId": "ab3deaeb-61c0-48e4-b442-aa0c30d606da"
   },
   "outputs": [],
   "source": [
    "spectral.fit(adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "cFN4Cc18CrIj",
    "outputId": "d42fad38-a896-4e76-a09e-94b7562d0745"
   },
   "outputs": [],
   "source": [
    "# eigenvalues (adding the first)\n",
    "eigenvalues = [1] + list(spectral.eigenvalues_)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(eigenvalues[:20], 'o')\n",
    "plt.title(\"Spectrum of the Transition Matrix\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Eigenvalue\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4oPSJqt6CrIk"
   },
   "outputs": [],
   "source": [
    "# eigenvectors\n",
    "eigenvectors = spectral.eigenvectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "-Y4AWFLlCrIl",
    "outputId": "9f97002c-52a1-49f1-f073-65f4af863735"
   },
   "outputs": [],
   "source": [
    "# display an eigenvector\n",
    "image = visualize_graph(adjacency, position, scores=eigenvectors[:, 0])\n",
    "SVG(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "jJ5cdulJG8Je",
    "outputId": "a4b5d0d3-4c40-429c-f77b-fdbfc75b8d61"
   },
   "outputs": [],
   "source": [
    "# visualize another eigenvector\n",
    "image = visualize_graph(adjacency, position, scores=eigenvectors[:, 3])\n",
    "SVG(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "VpC91VM2L3N_",
    "outputId": "b7f20150-7edf-4698-be39-5e4dfc0d1b71"
   },
   "outputs": [],
   "source": [
    "embedding_2d = eigenvectors[:, :2]  # first two dimensions of the embedding graph\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(embedding_2d[:, 0], embedding_2d[:, 1], c=labels_true, cmap='jet')\n",
    "plt.title(\"Spectral Embedding in 2D\")\n",
    "plt.xlabel(\"1st Eigenvector\")\n",
    "plt.ylabel(\"2nd Eigenvector\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "_xlNBz0JHTD1",
    "outputId": "c52e39a2-9f8a-41e8-d54e-67dca9cb6a6b"
   },
   "outputs": [],
   "source": [
    "# display the graph of the embedding in dimension 2\n",
    "spectral = Spectral(2)\n",
    "embedding = spectral.fit_transform(adjacency)\n",
    "image = visualize_graph(adjacency, position=embedding, labels=labels_true)\n",
    "SVG(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQdarhMjCrIl"
   },
   "source": [
    "## Openflights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oHx4Su_CrIm"
   },
   "source": [
    "We now consider a larger graph. We use spectral embedding in dimension 20 to cluster the graph by k-means in the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lX1NQkUCrIm"
   },
   "outputs": [],
   "source": [
    "dataset = openflights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DEoq_ef6CrIn"
   },
   "outputs": [],
   "source": [
    "adjacency = dataset.adjacency\n",
    "position = dataset.position\n",
    "names = dataset.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "9Lr7oWwiCrIo",
    "outputId": "3eaad476-5087-414c-b862-f7961d9e25b4"
   },
   "outputs": [],
   "source": [
    "image = visualize_graph(adjacency, position, width=800, height=400, node_size=3, display_edges=False)\n",
    "SVG(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZRiAQ7CCrIp"
   },
   "source": [
    "## To do\n",
    "\n",
    "* Display the same world map with 8 clusters found by k-means in the embedding space. You can use ``scikit-learn``for k-means.\n",
    "* Do the same without normalization on the unit sphere (``normalized=False``).<br> Interpret the results. <br>**Hint:** Compute the Euclidean norm of the centroid of each cluster in the embedding space.\n",
    "\n",
    "**Answer:** With the unnormalized embedding, clusters form mostly around how many connections each airport has, so a few airports dominate large groups and the rest are squeezed into smaller ones. With the normalized embedding, clusters depend on the relative positions of airports in the embedding, but some end up mixing airports from different regions. In both cases, because flight connections are uneven and overlap across areas, the resulting clusters are uneven in size and don't map neatly to geographic regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwTcaAfsCrIq"
   },
   "outputs": [],
   "source": [
    "spectral = Spectral(20, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1QtMGZuCrIq"
   },
   "outputs": [],
   "source": [
    "embedding = spectral.fit_transform(adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5ULStYSWsfy",
    "outputId": "01ff0185-d70e-4b24-b4fb-44335ce864c8"
   },
   "outputs": [],
   "source": [
    "# k means\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(8, random_state=0).fit(embedding)\n",
    "labels = kmeans.labels_\n",
    "normalized_centroid_norms = np.linalg.norm(kmeans.cluster_centers_, axis=1)\n",
    "print(\"Normalized Centroid Norms:\",normalized_centroid_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "kRQuejHlWsuJ",
    "outputId": "370bcfc0-a032-4900-a491-6b07bb8e2510"
   },
   "outputs": [],
   "source": [
    "# display the world map with 8 clusters found by k-means\n",
    "image = visualize_graph(adjacency, position,labels=labels,node_size=4, display_edges=False,width=800, height=400)\n",
    "SVG(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "5cFiR7j0Wswx",
    "outputId": "f54e236a-52e5-418e-f06b-af8d562a19f6"
   },
   "outputs": [],
   "source": [
    "# without normalization\n",
    "spectral = Spectral(20, normalized=False)\n",
    "embedding = spectral.fit_transform(adjacency)\n",
    "kmeans = KMeans(8, random_state=0).fit(embedding)\n",
    "labels = kmeans.labels_\n",
    "unnormalized_centroid_norms = np.linalg.norm(kmeans.cluster_centers_, axis=1)\n",
    "print(\"Unnormalized Centroid Norms:\",unnormalized_centroid_norms)\n",
    "image = visualize_graph(adjacency, position,labels=labels,node_size=4, display_edges=False,width=800, height=400)\n",
    "SVG(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvChp1eSCrIr"
   },
   "source": [
    "## 2. Directed graphs and bipartite graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fd5JDvMrCrIr"
   },
   "source": [
    "We now work on directed graph and bipartite graphs. We measure proximity between nodes in the embedding space in terms of [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity). Equivalently, we project the vectors on the unit sphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMSGaWHXCrIs"
   },
   "outputs": [],
   "source": [
    "spectral = Spectral(20, normalized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8LoVyvBCrIt"
   },
   "source": [
    "## Wikipedia Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4eYxkmo0CrIt"
   },
   "outputs": [],
   "source": [
    "dataset = wikivitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ZWT6vuOCrIv"
   },
   "outputs": [],
   "source": [
    "adjacency = dataset.adjacency\n",
    "biadjacency = dataset.biadjacency\n",
    "names = dataset.names\n",
    "words = dataset.names_col\n",
    "labels = dataset.labels\n",
    "names_labels = dataset.names_labels\n",
    "labels_hierarchy = dataset.labels_hierarchy\n",
    "names_labels_hierarchy = dataset.names_labels_hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Gx0FLvmCrIw"
   },
   "source": [
    "## To do\n",
    "\n",
    "We first consider the spectral embedding of the graph of links in dimension 20.\n",
    "\n",
    "* List the 20 articles that are closest to **Vincent van Gogh** in terms of cosine similarity in the embedding space. Compare with the top articles obtained with Personalized PageRank.\n",
    "* Display the 3D-plot of each of the 11 labels in the embedding space (top 3 dimensions). <br>You might represent each label by a point located at the centroid of the corresponding articles, with a size proportional to the number of articles. Use ``plotly`` for an interactive plot. Interpret the results.\n",
    "* Display the dendrogram of the hierarchical clustering of the top-100 articles on **Arts** (in terms of Personalized PageRank). You might use the [Ward method](https://en.wikipedia.org/wiki/Ward%27s_method) in the embedding space. Comment the results.\n",
    "\n",
    "**Answer:** \n",
    "* The closest articles to Vicent van Gogh through cosine similarity shows more articles in the field of arts, displaying mainly artists names, while on the list of page rank closest articles some more general and not so linked articles such as World War I and BBC also appears.\n",
    "* As we can see from the 3D plot the toppics in a Humanity field are closet to each other while Mathematics is far from all.\n",
    "* Through the dendogram we can see that the two bigger clusters are divided by a Music cluster and the second cluster divides itself through arts moviments, paintings and literature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHUQAtp-CrIw"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = 'notebook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_UhyDb2tb7q_"
   },
   "outputs": [],
   "source": [
    "embedding = spectral.fit_transform(adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tWtJJcQrb7uA",
    "outputId": "b8db0951-4de9-4b50-ab73-0767c83c20e6"
   },
   "outputs": [],
   "source": [
    "# closest articles to Van Gogh in terms of cosine similarity\n",
    "idx_vg = np.where(names == 'Vincent van Gogh')[0][0]\n",
    "cos_sim = np.matmul(embedding[idx_vg], embedding.T)/(np.linalg.norm(embedding[idx_vg])*np.linalg.norm(embedding, axis=1))\n",
    "top_20_names = top_k(cos_sim, 21)\n",
    "\n",
    "for name in top_20_names[1:]:\n",
    "    print(names[name])\n",
    "\n",
    "# top articles obtained with personalized pagerank\n",
    "pagerank = PageRank()\n",
    "scores = pagerank.fit_predict(adjacency, weights={idx_vg: 1})\n",
    "top_20_names_page = top_k(scores, 21)\n",
    "print(\"----------------------Personalized Page Rank------------------------\")\n",
    "for name in top_20_names_page[1:]:\n",
    "    print(names[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "wZrx-rlHb7wB",
    "outputId": "567ae1e0-2fa4-4782-bce2-fad093636e4c"
   },
   "outputs": [],
   "source": [
    "# 3D scatter of label centroids - first 3 dimensions\n",
    "unique_labels = np.unique(labels)\n",
    "centroids, counts, label_names = [], [], []\n",
    "for lab in unique_labels:\n",
    "    idxs = np.where(labels == lab)[0]\n",
    "    counts.append(len(idxs))\n",
    "    centroids.append(embedding[idxs, :3].mean(axis=0))\n",
    "    label_names.append(names_labels[lab])\n",
    "centroids = np.array(centroids)\n",
    "df = {\n",
    "    'x': centroids[:, 0], 'y': centroids[:, 1], 'z': centroids[:, 2],\n",
    "    'label': label_names, 'count': counts\n",
    "}\n",
    "fig = px.scatter_3d(df, x='x', y='y', z='z', text='label', size='count',\n",
    "                    title='3D Centroids of 11 Wikivitals Labels')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "y822GvhCb7ya",
    "outputId": "52f95b8f-6341-4a1f-f498-4ff95a0f018b"
   },
   "outputs": [],
   "source": [
    "from sknetwork.visualization import visualize_graph, visualize_dendrogram\n",
    "# Dendrogram of top-100 Arts articles by global PageRank\n",
    "arts_label = np.where(names_labels == 'Arts')[0][0]\n",
    "scores = pagerank.fit_predict(adjacency, weights = labels == arts_label)\n",
    "scores[np.where(labels != arts_label)] = 0\n",
    "top_100 = top_k(scores, 100)\n",
    "\n",
    "dendrogram = linkage(embedding[top_100], method=\"ward\")\n",
    "\n",
    "image = visualize_dendrogram(dendrogram, names=names[top_100], rotate=True, rotate_names=True, height=1000)\n",
    "SVG(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GebCciJmCrIx"
   },
   "source": [
    "## To do\n",
    "\n",
    "* Repeat the same experiments on the bipartite graph between articles and words.\n",
    "* List the 10 articles and the 10 words that are closest to the word **painting** in the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hhiubikWunbV"
   },
   "outputs": [],
   "source": [
    "embedding = spectral.fit_transform(biadjacency, force_bipartite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GiRqG_8Yunjl",
    "outputId": "5e5ac55b-cb52-43e7-bc6e-2f77b4fc6a3f"
   },
   "outputs": [],
   "source": [
    "# closest articles to Van Gogh in terms of cosine similarity\n",
    "idx_vg = np.where(names == 'Vincent van Gogh')[0][0]\n",
    "cos_sim = np.matmul(embedding[idx_vg], embedding.T)/(np.linalg.norm(embedding[idx_vg])*np.linalg.norm(embedding, axis=1))\n",
    "top_20_names = top_k(cos_sim, 21)\n",
    "\n",
    "for name in top_20_names[1:]:\n",
    "    print(names[name])\n",
    "\n",
    "# top articles obtained with personalized pagerank\n",
    "pagerank = PageRank()\n",
    "scores = pagerank.fit_predict(biadjacency, weights={idx_vg: 1})\n",
    "top_20_names_page = top_k(scores, 21)\n",
    "print(\"----------------------Personalized Page Rank------------------------\")\n",
    "for name in top_20_names_page[1:]:\n",
    "    print(names[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f8Dgs-zw0AP",
    "outputId": "b13a353b-e475-402c-ca03-8b37e5de7a10"
   },
   "outputs": [],
   "source": [
    "print(\"---------------Top 10 Articles-----------------\")\n",
    "embedding_words = spectral.embedding_col_\n",
    "embedding_painting = embedding_words[np.where(words == 'painting')[0][0]]\n",
    "\n",
    "cos_sim = np.matmul(embedding_painting, embedding.T)/(np.linalg.norm(embedding_painting)*np.linalg.norm(embedding, axis=1))\n",
    "top_10_names = top_k(cos_sim, 11)\n",
    "\n",
    "for name in top_10_names[1:]:\n",
    "    print(names[name])\n",
    "\n",
    "print(\"---------------Top 10 Words-----------------\")\n",
    "cos_sim = np.matmul(embedding_painting, embedding_words.T)/(np.linalg.norm(embedding_painting)*np.linalg.norm(embedding_words, axis=1))\n",
    "top_10_words = top_k(cos_sim, 10)\n",
    "\n",
    "for word in top_10_words:\n",
    "    print(words[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pU5BMJqxunwb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHyoVb6oCrIy"
   },
   "source": [
    "## To do\n",
    "\n",
    "* Prove that the average cosine similarity between vectors in some set $S$ is equal to the square norm of the centroid of $S$.\n",
    "\n",
    "$$\n",
    "S=\\{v_1,\\ldots,v_n\\}\n",
    "$$\n",
    "$$\n",
    "\\mu = \\frac 1 n \\sum_{i=1}^n v_i\n",
    "$$\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "The average cosine similarity is given by:\n",
    "\n",
    "$$\n",
    "\\frac 1 {n^2} \\sum_{i=1}^n \\sum_{j=1}^n \\frac {v_i \\cdot v_j}{\\|v_i\\|\\cdot\\|v_j\\|}\n",
    "$$\n",
    "\n",
    "From that we can develop:\n",
    "\n",
    "$$\n",
    "\\frac {1}{\\|v_i\\|\\cdot\\|v_j\\|} \\underbrace{\\frac 1 n \\sum_{i=1}^n v_i}_{\\mu} \\cdot \\underbrace{\\frac 1 n \\sum_{j=1}^n  v_j}_{\\mu} = \\frac {1}{\\|v_i\\|\\cdot\\|v_j\\|}\\mu \\cdot \\mu = \\frac {1}{\\|v_i\\|\\cdot\\|v_j\\|} \\|\\mu\\|^2\n",
    "$$\n",
    "\n",
    "If we consider $\\|v\\|=1$:\n",
    "\n",
    "$$\n",
    "\\frac 1 {n^2} \\sum_{i=1}^n \\sum_{j=1}^n {v_i \\cdot v_j} = \\|\\mu\\|^2\n",
    "$$\n",
    "\n",
    "For the following questions, first consider the graph of links, then the bipartite graph between articles and words:\n",
    "\n",
    "* Compute the average cosine similarity between articles of the **Mammals** category (see hierarchical labels).\n",
    "* Compare with the expected cosine similarity between two articles sampled uniformly at random.\n",
    "* Defining a category as **topical** if its average cosine similarity is close to 1, rank the 11 categories (Arts, History,...) by topicality.\n",
    "* List the 10 most topical and the 10 less topical hierarchical categories having at least 10 articles (like **Mammals**). Comment the results.\n",
    "\n",
    "\n",
    "**Answer:** Overall, embedding the bipartite graph of articles and words yields more coherent topical clusters than the link-graph embedding alone: hierarchical labels carve articles into tighter groups, and their topicality scores (the squared norm of each categoryâ€™s centroid) are consistently higher under the bipartite embedding.\n",
    "\n",
    "as we can see , by taking the topicallity of the general categories in name_labels we have a smaller result than by taking into consideration all the categories with at least 10 articles. Even so, by taking the ranking of topical with the general categories, we can see some predominance of top categories such as Physical Sciences that repeats itself in other subcategories.\n",
    "\n",
    "We can also notice that in the case of bipartites we get to have slightely smaller results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4CdCMxnCrIz"
   },
   "outputs": [],
   "source": [
    "# average cosine similarity \n",
    "embedding = spectral.fit_transform(adjacency)\n",
    "mammal_idx = [i for i, name in enumerate(names_labels_hierarchy) if 'Mammals' in name][0]\n",
    "is_mammal = (labels_hierarchy == mammal_idx)\n",
    "centroid = embedding[is_mammal].mean(axis=0)\n",
    "avg_cosine = np.dot(centroid, centroid)\n",
    "print(\"Average cosine similarity for Mammals in the graph of links:\", avg_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected cosine similarity between two articles sampled uniformly\n",
    "expect_cosine = np.dot(embedding.mean(axis=0), embedding.mean(axis=0))\n",
    "print(\"Expected cosine similarity for two articles sampled uniformly:\", expect_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"List by topicality:\")\n",
    "avgs = {}\n",
    "for category, label in enumerate(names_labels):\n",
    "    is_category = (labels == category)\n",
    "    centroid = embedding[is_category].mean(axis=0)\n",
    "    avg_cosine = np.dot(centroid, centroid)\n",
    "    avgs[label] = avg_cosine\n",
    "sorted_avgs = {k: v for k, v in sorted(avgs.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "for key, value in sorted_avgs.items():\n",
    "    print(f\"{key} : {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = np.unique(labels_hierarchy,return_counts=True)[1] >= 10\n",
    "\n",
    "avgs = {}\n",
    "for category in np.unique(names_labels_hierarchy[mask]):    \n",
    "    category_idx = [i for i, name in enumerate(names_labels_hierarchy) if category in name][0]\n",
    "    is_category = (labels_hierarchy == category_idx)\n",
    "    centroid = embedding[is_category].mean(axis=0)\n",
    "    avg_cosine = np.dot(centroid, centroid)\n",
    "    avgs[category] = avg_cosine\n",
    "\n",
    "print(\"10 top:\")\n",
    "sorted_avgs = {k: v for k, v in sorted(avgs.items(), key=lambda item: item[1], reverse=True)}\n",
    "for key, value in list(sorted_avgs.items())[:10]:\n",
    "    print(f\"{key} : {value}\")\n",
    "print(\"\\n-------------------------\\n\")\n",
    "print(\"10 least: \")\n",
    "sorted_avgs = {k: v for k, v in sorted(avgs.items(), key=lambda item: item[1], reverse=False)}\n",
    "for key, value in list(sorted_avgs.items())[:10]:\n",
    "    print(f\"{key} : {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bipartite\n",
    "\n",
    "# average cosine similarity \n",
    "embedding = spectral.fit_transform(biadjacency, force_bipartite=True)\n",
    "mammal_idx = [i for i, name in enumerate(names_labels_hierarchy) if 'Mammals' in name][0]\n",
    "is_mammal = (labels_hierarchy == mammal_idx)\n",
    "centroid = embedding[is_mammal].mean(axis=0)\n",
    "avg_cosine = np.dot(centroid, centroid)\n",
    "print(\"Average cosine similarity for Mammals in the graph of links:\", avg_cosine)\n",
    "\n",
    "# Expected cosine similarity between two articles sampled uniformly\n",
    "expect_cosine = np.dot(embedding.mean(axis=0), embedding.mean(axis=0))\n",
    "print(\"Expected cosine similarity for two articles sampled uniformly:\", expect_cosine)\n",
    "\n",
    "print(\"\\n-------------------------\\n\")\n",
    "\n",
    "print(\"List by topicality:\")\n",
    "avgs = {}\n",
    "for category, label in enumerate(names_labels):\n",
    "    is_category = (labels == category)\n",
    "    centroid = embedding[is_category].mean(axis=0)\n",
    "    avg_cosine = np.dot(centroid, centroid)\n",
    "    avgs[label] = avg_cosine\n",
    "sorted_avgs = {k: v for k, v in sorted(avgs.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "for key, value in sorted_avgs.items():\n",
    "    print(f\"{key} : {value}\")\n",
    "\n",
    "\n",
    "print(\"\\n-------------------------\\n\")\n",
    "mask = np.unique(labels_hierarchy,return_counts=True)[1] >= 10\n",
    "\n",
    "avgs = {}\n",
    "for category in np.unique(names_labels_hierarchy[mask]):    \n",
    "    category_idx = [i for i, name in enumerate(names_labels_hierarchy) if category in name][0]\n",
    "    is_category = (labels_hierarchy == category_idx)\n",
    "    centroid = embedding[is_category].mean(axis=0)\n",
    "    avg_cosine = np.dot(centroid, centroid)\n",
    "    avgs[category] = avg_cosine\n",
    "\n",
    "print(\"10 top:\")\n",
    "sorted_avgs = {k: v for k, v in sorted(avgs.items(), key=lambda item: item[1], reverse=True)}\n",
    "for key, value in list(sorted_avgs.items())[:10]:\n",
    "    print(f\"{key} : {value}\")\n",
    "print(\"\\n-------------------------\\n\")\n",
    "print(\"10 least: \")\n",
    "sorted_avgs = {k: v for k, v in sorted(avgs.items(), key=lambda item: item[1], reverse=False)}\n",
    "for key, value in list(sorted_avgs.items())[:10]:\n",
    "    print(f\"{key} : {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
